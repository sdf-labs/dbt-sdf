# generated by datamodel-codegen:
#   filename:  schema.json
#   timestamp: 2024-08-26T01:52:53+00:00

from __future__ import annotations

from enum import Enum
from typing import Any, Dict, List, Optional, Union

from dbt_sdf.schema.base import BaseModel
from pydantic import Extra, Field, conint


class IncludeType1(Enum):
    model = 'model'


class IncludeType2(Enum):
    test = 'test'


class IncludeType3(Enum):
    check = 'check'


class IncludeType4(Enum):
    report = 'report'


class IncludeType5(Enum):
    stat = 'stat'


class IncludeType6(Enum):
    resource = 'resource'


class IncludeType7(Enum):
    metadata = 'metadata'


class IncludeType8(Enum):
    spec = 'spec'


class IncludeType9(Enum):
    macro = 'macro'


class IncludeType10(Enum):
    seed = 'seed'


class IndexMethod1(Enum):
    scan_dbt = 'scan-dbt'


class IndexMethod2(Enum):
    none = 'none'


class IndexMethod3(Enum):
    table_name = 'table-name'


class IndexMethod4(Enum):
    schema_table_name = 'schema-table-name'


class IndexMethod5(Enum):
    catalog_schema_table_name = 'catalog-schema-table-name'


class Dialect(Enum):
    snowflake = 'snowflake'
    trino = 'trino'
    bigquery = 'bigquery'
    redshift = 'redshift'
    spark_lp = 'spark-lp'


class Preprocessor(Enum):
    none = 'none'
    jinja = 'jinja'
    sql_vars = 'sql-vars'
    sql_logic_test = 'sql-logic-test'
    all = 'all'


class Materialization1(Enum):
    table = 'table'


class Materialization2(Enum):
    transient_table = 'transient-table'


class Materialization3(Enum):
    temporary_table = 'temporary-table'


class Materialization4(Enum):
    external_table = 'external-table'


class Materialization5(Enum):
    view = 'view'


class Materialization6(Enum):
    materialized_view = 'materialized-view'


class Materialization7(Enum):
    incremental_table = 'incremental-table'


class Materialization8(Enum):
    snapshot_table = 'snapshot-table'


class Materialization9(Enum):
    recursive_table = 'recursive-table'


class Materialization10(BaseModel):
    class Config:
        extra = 'forbid'

    other: str


class TableCreationFlags1(Enum):
    create_new = 'create-new'


class TableCreationFlags2(Enum):
    drop_if_exists = 'drop-if-exists'


class TableCreationFlags3(Enum):
    skip_if_exists = 'skip-if-exists'


class TableCreationFlags4(Enum):
    create_or_replace = 'create-or-replace'


class TableCreationFlags5(Enum):
    create_if_not_exists = 'create-if-not-exists'


class SyncType1(Enum):
    always = 'always'


class SyncType2(Enum):
    on_pull = 'on-pull'


class SyncType3(Enum):
    on_push = 'on-push'


class SyncType4(Enum):
    never = 'never'


class Severity(Enum):
    warning = 'warning'
    error = 'error'


class CompressionType1(Enum):
    tar = 'tar'
    zstd = 'zstd'


class CompressionType2(Enum):
    bzip2 = 'bzip2'


class CompressionType3(Enum):
    gzip = 'gzip'


class CompressionType4(Enum):
    none = 'none'


class ExcludeType1(Enum):
    content = 'content'


class ExcludeType2(Enum):
    path = 'path'


class Dependency(BaseModel):
    class Config:
        extra = 'forbid'

    name: str
    path: Optional[str] = Field(
        None,
        description='The relative path from this workspace to the referenced workspace, for a Git repo, from the root of the depot to the workspace',
    )
    environment: Optional[str] = Field(
        None, description='The chosen workspace environment (none means default)'
    )
    target: Optional[str] = Field(
        None, description='The chosen workspace target (none means default)'
    )
    git: Optional[str] = Field(None, description='The Git repo')
    rev: Optional[str] = Field(
        None,
        description='the Git revision (choose only one of the fields: rev, branch, tag)',
    )
    branch: Optional[str] = Field(
        None,
        description='the Git branch (choose only one of the fields: rev, branch, tag)',
    )
    tag: Optional[str] = Field(
        None,
        description='the Git tag (choose only one of the fields: rev, branch, tag)',
    )
    imports: Optional[List[str]] = Field(
        None,
        description='Which models, reports, tests, checks etc. to include from the dependency',
    )


class IntegrationType(Enum):
    data = 'data'
    metadata = 'metadata'
    database = 'database'


class ProviderType(Enum):
    glue = 'glue'
    redshift = 'redshift'
    snowflake = 'snowflake'
    s3 = 's3'
    sdf = 'sdf'


class SourcePattern(BaseModel):
    class Config:
        extra = 'forbid'

    pattern: str = Field(
        ...,
        description='A source that can be read. Sources must be a three part names with globs, eg. *.*.* matches all catalogs, schema and table in scope',
    )
    time_travel_qualifier: Optional[str] = Field(
        None,
        alias='time-travel-qualifier',
        description='Time travel qualifier expression (e.g. `AT (TIMESTAMP => {{ SOME_TIMESTAMP }})``)',
    )
    preload: Optional[bool] = Field(None, description='Whether to preload the source')
    rename_from: Optional[str] = Field(
        None,
        alias='rename-from',
        description='Renames sources when searching in the remote, the ith ${i} matches the ith * of the name, so to prepend all catalogs,schema,table with _, use "_${1}._${2}._${3}"',
    )


class TargetPattern(BaseModel):
    class Config:
        extra = 'forbid'

    pattern: Optional[str] = Field(
        None,
        description='A pattern must be a three part names with globs, eg. *.*.* matches all catalogs, schema and table in scope',
    )
    patterns: Optional[List[str]] = Field(
        None,
        description='A list of patterns. A pattern must be a three part names with globs, eg. *.*.* matches all catalogs, schema and table in scope',
    )
    preload: Optional[bool] = Field(None, description='Whether to preload the target')
    rename_as: Optional[str] = Field(
        None,
        alias='rename-as',
        description='Renames targets, the ith ${i} matches the ith * of the name, so to prepend all catalogs,schema,table with _, use "_${1}._${2}._${3}"',
    )


class DataBucket(BaseModel):
    class Config:
        extra = 'forbid'

    uri: str = Field(..., description='The uri of the bucket')
    region: Optional[str] = Field(None, description='The region of the bucket')


class SystemTime(BaseModel):
    secs_since_epoch: conint(ge=0)
    nanos_since_epoch: conint(ge=0)


class TablePurpose1(Enum):
    report = 'report'


class TablePurpose2(Enum):
    model = 'model'


class TablePurpose3(Enum):
    check = 'check'


class TablePurpose4(Enum):
    test = 'test'


class TablePurpose5(Enum):
    stat = 'stat'


class TablePurpose6(Enum):
    system = 'system'


class TablePurpose7(Enum):
    external_system = 'external-system'


class TableOrigin(Enum):
    local = 'local'
    remote = 'remote'


class TableLocation(Enum):
    mirror = 'mirror'
    local = 'local'
    remote = 'remote'
    intrinsic = 'intrinsic'


class IncrementalStrategy(Enum):
    append = 'append'
    merge = 'merge'
    delete_insert = 'delete+insert'


class OnSchemaChange1(Enum):
    fail = 'fail'


class OnSchemaChange2(Enum):
    append = 'append'


class OnSchemaChange3(Enum):
    sync = 'sync'


class SnapshotStrategy(Enum):
    timestamp = 'timestamp'
    check = 'check'


class CheckColsSpec1(BaseModel):
    class Config:
        extra = 'forbid'

    cols: List[str]


class CheckColsSpec2(Enum):
    all = 'all'


class Lineage(BaseModel):
    class Config:
        extra = 'forbid'

    copy_: Optional[List[str]] = Field(
        None,
        alias='copy',
        description='The output column is computed by copying these upstream columns',
    )
    modify: Optional[List[str]] = Field(
        None,
        description='The output column is computed by transforming these upstream columns',
    )
    scan: Optional[List[str]] = Field(
        None,
        description='These upstream columns are indirectly used to produce the output (e.g. in WHERE or GROUP BY)',
    )
    apply: Optional[List[str]] = Field(
        None, description='These functions were used to produce the output column'
    )


class Reclassify(BaseModel):
    class Config:
        extra = 'forbid'

    to: Optional[str] = Field(None, description='Target classifier')
    from_: Optional[str] = Field(
        None, alias='from', description='Expected source classifier'
    )


class Constraint(BaseModel):
    class Config:
        extra = 'forbid'

    expect: str = Field(
        ...,
        description='The constraint macro: must have the form lib.macro(args,..), where lib is any of the libs in scope, std is available by default',
    )
    severity: Optional[Severity] = Field(
        None, description='The severity of this constraint'
    )


class Partition(BaseModel):
    class Config:
        extra = 'forbid'

    name: str = Field(..., description='The name of the partition column')
    description: Optional[str] = Field(
        None, description='A description of the partition column'
    )
    format: Optional[str] = Field(
        None,
        description='The format of the partition column [use strftime format for date/time] See (guide)[https://docs.sdf.com/guide/schedules]',
    )


class FileFormat(Enum):
    parquet = 'parquet'
    csv = 'csv'
    json = 'json'


class Label(BaseModel):
    class Config:
        extra = 'forbid'

    name: str = Field(
        ...,
        description='The name of the label, use "*" to allow arbitrary strings as labels',
    )
    description: Optional[str] = Field(
        None, description='A description of this classifier element'
    )


class Scope(Enum):
    column = 'column'
    table = 'table'


class Cardinality(Enum):
    zero_or_one = 'zero-or-one'
    one = 'one'
    zero_or_more = 'zero-or-more'


class Variadic1(Enum):
    non_uniform = 'non-uniform'


class Variadic2(Enum):
    uniform = 'uniform'


class Variadic3(Enum):
    even_odd = 'even-odd'


class Variadic4(Enum):
    any = 'any'


class FunctionKind(Enum):
    scalar = 'scalar'
    aggregate = 'aggregate'
    window = 'window'
    table = 'table'


class Parameter(BaseModel):
    class Config:
        extra = 'forbid'

    name: Optional[str] = Field(None, description='The name of the parameter')
    description: Optional[str] = Field(
        None, description='A description of this parameter'
    )
    datatype: Optional[str] = Field(None, description='The datatype of this parameter')
    classifier: Optional[List[str]] = Field(
        None, description='An array of classifier references'
    )
    constant: Optional[str] = Field(
        None, description='The required constant value of this parameter'
    )
    identifiers: Optional[List[str]] = Field(
        None, description='The parameter may appear as identifier, without quote'
    )


class OptionalParameter(BaseModel):
    class Config:
        extra = 'forbid'

    name: str = Field(..., description='The name of the parameter')
    description: Optional[str] = Field(
        None, description='A description of this parameter'
    )
    datatype: str = Field(..., description='The datatype of this parameter')
    classifier: Optional[List[str]] = Field(
        None, description='An array of classifier references'
    )
    constant: Optional[str] = Field(
        None, description='The required constant value of this parameter'
    )
    identifiers: Optional[List[str]] = Field(
        None, description='The parameter may appear as identifier, without quote'
    )


class TypeBound(BaseModel):
    class Config:
        extra = 'forbid'

    type_variable: str = Field(..., alias='type-variable')
    datatypes: List[str]


class Volatility1(Enum):
    pure = 'pure'


class Volatility2(Enum):
    stable = 'stable'


class Volatility3(Enum):
    volatile = 'volatile'


class Example(BaseModel):
    class Config:
        extra = 'forbid'

    input: str = Field(
        ..., description='The sql string corresponding to the input of this example'
    )
    output: str = Field(
        ..., description='The output corresponding to running the input string'
    )


class FunctionImplSpec1(Enum):
    builtin = 'builtin'


class FunctionImplSpec4(Enum):
    sql = 'sql'


class RustFunctionSpec(BaseModel):
    class Config:
        extra = 'forbid'

    name: Optional[str] = Field(
        None,
        description='The name attribute of the implementing UDF. None indicates the UDF is named the same as the function.',
    )


class DataFusionSpec(BaseModel):
    class Config:
        extra = 'forbid'

    udf: Optional[str] = Field(
        None,
        description='The name attribute of the implementing UDF. None indicates the UDF is named the same as the function.',
    )


class Config(BaseModel):
    class Config:
        extra = 'forbid'

    name: str = Field(..., description='The name of the configuration section')
    description: Optional[str] = Field(
        None, description='A description of this configuration section'
    )
    properties: Optional[Dict[str, Any]] = None


class Type(Enum):
    sdf = 'sdf'


class Type2(Enum):
    snowflake = 'snowflake'


class Type3(Enum):
    aws = 'aws'


class Type4(Enum):
    openai = 'openai'


class Type5(Enum):
    empty = 'empty'


class SdfAuthVariant(Enum):
    interactive = 'interactive'
    headless = 'headless'
    id_token_from_file = 'id_token_from_file'


class HeadlessCredentials(BaseModel):
    access_key: str
    secret_key: str


class LayoutRules(BaseModel):
    pass

    class Config:
        extra = 'forbid'


class Capitalization(Enum):
    upper = 'upper'
    lower = 'lower'
    pascal = 'pascal'
    snake = 'snake'
    camel = 'camel'
    consistent = 'consistent'


class RuleOn(Enum):
    on = 'on'


class ColumnQualifier(Enum):
    qualified = 'qualified'
    unqualified = 'unqualified'
    consistent = 'consistent'


class SubQueryScope(Enum):
    join = 'join'
    from_ = 'from'


class ImplicitConversionOperators(Enum):
    eq = 'eq'
    in_ = 'in'


class PerformanceRules(BaseModel):
    class Config:
        extra = 'forbid'

    flag_function_application_in_where_on_indexed_columns: Optional[RuleOn] = Field(
        None,
        alias='flag-function-application-in-where-on-indexed-columns',
        description='Avoid functions in where clauses over indexed, partitioned or clustered columns, to prevent filter push down and improve performance ',
    )


class Defaults(BaseModel):
    class Config:
        extra = 'forbid'

    environment: Optional[str] = Field(
        None,
        description='The default environment (can only be set on the level of the workspace)',
    )
    dialect: Optional[Dialect] = Field(
        None,
        description='The dialect of this environment. If not set, defaults to trino',
    )
    preprocessor: Optional[Preprocessor] = Field(
        None,
        description='The preprocessor for this environment. If not set, defaults to local',
    )
    catalog: Optional[str] = Field(
        None,
        description='Defines a default catalog. If not set, defaults to the (catalog/workspace) name in an outer scope',
    )
    schema_: Optional[str] = Field(
        None,
        alias='schema',
        description="Defines a default schema,  If not set, defaults to the schema name in an outer scope, if not set, defaults to 'pub'",
    )
    materialization: Optional[
        Union[
            Materialization1,
            Materialization2,
            Materialization3,
            Materialization4,
            Materialization5,
            Materialization6,
            Materialization7,
            Materialization8,
            Materialization9,
            Materialization10,
        ]
    ] = Field(
        None,
        description='Defines the default materialization, if not set defaults to materialization in outer scope, if not set defaults to base-table',
    )
    creation_flag: Optional[
        Union[
            TableCreationFlags1,
            TableCreationFlags2,
            TableCreationFlags3,
            TableCreationFlags4,
            TableCreationFlags5,
        ]
    ] = Field(
        None,
        alias='creation-flag',
        description='Defines table creation flags, defaults to  if not set',
    )
    utils_lib: Optional[str] = Field(
        None,
        alias='utils-lib',
        description='The default utils library, if set overrides sdf_utils',
    )
    test_lib: Optional[str] = Field(
        None,
        alias='test-lib',
        description='The default test library, if set overrides sdf_test',
    )
    materialization_lib: Optional[str] = Field(
        None,
        alias='materialization-lib',
        description='The default materialization library, if set overrides sdf_materialization',
    )
    linter: Optional[str] = Field(
        None,
        description='The named lint rule set, uses defaults (from sdftarget/<environment>/lint.sdf.yml) if not set',
    )
    index_method: Optional[
        Union[IndexMethod1, IndexMethod2, IndexMethod3, IndexMethod4, IndexMethod5]
    ] = Field(
        None, alias='index-method', description='The default index for this tables'
    )
    include_type: Optional[
        Union[
            IncludeType1,
            IncludeType2,
            IncludeType3,
            IncludeType4,
            IncludeType5,
            IncludeType6,
            IncludeType7,
            IncludeType8,
            IncludeType9,
            IncludeType10,
        ]
    ] = Field(
        None, alias='include-type', description='The default index for this tables'
    )
    sync_method: Optional[Union[SyncType1, SyncType2, SyncType3, SyncType4]] = Field(
        None, alias='sync-method', description='The default index for this tables'
    )
    severity: Optional[Severity] = Field(
        None, description='The default severity for this tables tests and checks'
    )
    csv_has_header: Optional[bool] = Field(
        None,
        alias='csv-has-header',
        description='CSV data has a header [only for external tables]',
    )
    csv_delimiter: Optional[str] = Field(
        None,
        alias='csv-delimiter',
        description='CSV data is separated by this delimiter [only for external tables]',
    )
    csv_compression: Optional[
        Union[CompressionType1, CompressionType2, CompressionType3, CompressionType4]
    ] = Field(
        None,
        alias='csv-compression',
        description='Json or CSV data is compressed with this method [only for external tables]',
    )


class ExcludePath(BaseModel):
    class Config:
        extra = 'forbid'

    path: str = Field(..., description='A filepath')
    exclude_type: Optional[Union[ExcludeType1, ExcludeType2]] = Field(
        None, alias='exclude-type', description='Type of excluded artifacts'
    )


class Integration(BaseModel):
    class Config:
        extra = 'forbid'

    type: Optional[IntegrationType] = Field(
        'database',
        description='The type of the integration [e.g.: database, metadata, data]',
    )
    provider: ProviderType = Field(
        ..., description='The type of the provider [e.g.: snowflake, redshift, s3]'
    )
    credential: Optional[str] = Field(
        None, description='Credential identifier for this provider'
    )
    cluster_identifier: Optional[str] = Field(
        None,
        alias='cluster-identifier',
        description='The cluster identifier for redshift server',
    )
    batch_size: Optional[conint(ge=0)] = Field(
        None,
        alias='batch-size',
        description='The size of the batch when querying the provider',
    )
    sources: Optional[List[SourcePattern]] = Field(
        None,
        description='A list of (possibly remote) sources to read, matched in order, so write specific pattern before more general patterns',
    )
    targets: Optional[List[TargetPattern]] = Field(
        None,
        description='A list of (possibly remote) targets to build,  matched in order, so write specific pattern before more general patterns, source patterns are excluded',
    )
    buckets: Optional[List[DataBucket]] = Field(
        None, description='A list of remote buckets to target'
    )
    output_location: Optional[str] = Field(
        None,
        alias='output-location',
        description='The remote output location of the integration',
    )


class FilePath(BaseModel):
    class Config:
        extra = 'forbid'

    path: str = Field(..., description='A filepath')
    time: Optional[SystemTime] = Field(None, description='Last modified of the file')


class IncrementalOptions(BaseModel):
    class Config:
        extra = 'forbid'

    strategy: IncrementalStrategy = Field(
        ...,
        description='Incremental strategy; may be one of `append`, `merge`, or `delete+insert`',
    )
    unique_key: Optional[str] = Field(
        None,
        alias='unique-key',
        description='Expression used for identifying records in Merge and Delete+Insert strategies; May be a column name or an expression combining multiple columns. If left unspecified, Merge and Delete+Insert strategies behave the same as Append',
    )
    merge_update_columns: Optional[List[str]] = Field(
        None,
        alias='merge-update-columns',
        description='List of column names to be updated as part of Merge strategy; Only one of merge_update_columns or merge_exclude_columns may be specified',
    )
    merge_exclude_columns: Optional[List[str]] = Field(
        None,
        alias='merge-exclude-columns',
        description='List of column names to exclude from updating as part of Merge strategy; Only one of merge_update_columns or merge_exclude_columns may be specified',
    )
    on_schema_change: Optional[
        Union[OnSchemaChange1, OnSchemaChange2, OnSchemaChange3]
    ] = Field(
        None,
        alias='on-schema-change',
        description='Method for reacting to changing schema in the source of the incremental table Possible values are `fail`, `append`, and `sync`. If left unspecified, the default behavior is to ignore the change and possibly error out if the schema change is incompatible. `fail` causes a failure whenever any deviation in the schema of the source is detected; `append` adds new columns but does not delete the columns removed from the source; `sync` adds new columns and deletess the columns removed from the source;',
    )


class SnapshotOptions(BaseModel):
    class Config:
        extra = 'forbid'

    strategy: SnapshotStrategy = Field(
        ...,
        description='Snapshot strategy; may be one of `timestamp` (default), or `check`',
    )
    unique_key: str = Field(
        ...,
        alias='unique-key',
        description='Expression used for identifying records that will be updated according to the snapshot strategiy; May be a column name or an expression combining multiple columns',
    )
    updated_at: Optional[str] = Field(
        None,
        alias='updated-at',
        description='Name of the timestamp column used to identify the last update time This option is only required for the `timestamp` snapshot strategy',
    )
    check_cols: Optional[Union[CheckColsSpec1, CheckColsSpec2]] = Field(
        None,
        alias='check-cols',
        description='Specification of which columns to check for change (may be a list of column names or `all`) This option is only required for the `check` snapshot strategy',
    )


class Column(BaseModel):
    class Config:
        extra = 'forbid'

    name: str = Field(..., description='The name of the column')
    description: Optional[str] = Field(None, description='A description of this column')
    datatype: Optional[str] = Field(None, description='The type of this column')
    classifiers: Optional[List[str]] = Field(
        None, description='An array of classifier references'
    )
    lineage: Optional[Lineage] = Field(
        None, description='Lineage, a tagged array of column references'
    )
    forward_lineage: Optional[Lineage] = Field(
        None,
        alias='forward-lineage',
        description='Forward Lineage, the columns that this column is used to compute',
    )
    reclassify: Optional[List[Reclassify]] = Field(
        None,
        description='Array of reclassify instructions for changing the attached classifier labels',
    )
    samples: Optional[List[str]] = Field(
        None,
        description='An array of representative literals of this column [experimental!]',
    )
    default_severity: Optional[Severity] = Field(
        None,
        alias='default-severity',
        description='The default severity for this tables tests and checks',
    )
    tests: Optional[List[Constraint]] = None


class Classifier(BaseModel):
    class Config:
        extra = 'forbid'

    name: str = Field(..., description='The name of the classifier type')
    description: Optional[str] = Field(
        None, description='A description of this classifier type'
    )
    labels: Optional[List[Label]] = Field(None, description='Named classifier labels')
    scope: Optional[Scope] = Field(
        None, description='Scope of the classifier: table or column'
    )
    cardinality: Optional[Cardinality] = Field(
        None,
        description='Cardinality of the classifier: zero-or-one, one or zero-or-many',
    )
    propagate: Optional[bool] = Field(
        None,
        description='Does the classifier propagate from scope to scope or is it a one scope marker',
    )
    source_locations: Optional[List[FilePath]] = Field(
        None,
        alias='source-locations',
        description='Classifier defined by these set of .sdf files',
    )


class FunctionImplSpec2(BaseModel):
    class Config:
        extra = 'forbid'

    rust: RustFunctionSpec


class FunctionImplSpec3(BaseModel):
    class Config:
        extra = 'forbid'

    datafusion: DataFusionSpec


class Credential1(BaseModel):
    name: str = Field(
        ..., description="The name of the credential (default = 'default')"
    )
    description: Optional[str] = Field(
        None, description='A description of this credential'
    )
    source_locations: Optional[List[FilePath]] = Field(
        None,
        alias='source-locations',
        description='Credential defined by these set of .sdf files',
    )
    type: Type
    variant: SdfAuthVariant = Field(..., description='Variant of the credential')
    headless_creds: Optional[HeadlessCredentials] = Field(
        None, alias='headless-creds', description='Headless Credentials'
    )


class Credential2(BaseModel):
    name: str = Field(
        ..., description="The name of the credential (default = 'default')"
    )
    description: Optional[str] = Field(
        None, description='A description of this credential'
    )
    source_locations: Optional[List[FilePath]] = Field(
        None,
        alias='source-locations',
        description='Credential defined by these set of .sdf files',
    )
    type: Type2
    account_id: str = Field(
        ...,
        alias='account-id',
        description='The account id of your snowflake account (e.g. <orgname>.<accountname> or <locator>)',
    )
    username: str = Field(..., description='The user name to connect to snowflake')
    password: str = Field(..., description='The password to connect to snowflake')
    role: Optional[str] = Field(None, description='The role to use for the connection')
    warehouse: Optional[str] = Field(
        None, description='The warehouse to use for the connection'
    )


class Credential3(BaseModel):
    name: str = Field(
        ..., description="The name of the credential (default = 'default')"
    )
    description: Optional[str] = Field(
        None, description='A description of this credential'
    )
    source_locations: Optional[List[FilePath]] = Field(
        None,
        alias='source-locations',
        description='Credential defined by these set of .sdf files',
    )
    type: Type3
    profile: Optional[str] = Field(
        None, description='The name of th profile to use in the AWS credentials file'
    )
    default_region: Optional[str] = Field(
        None,
        alias='default-region',
        description='The default region to use for this profile',
    )
    role_arn: Optional[str] = Field(
        None, alias='role-arn', description='The arn of the role to assume'
    )
    external_id: Optional[str] = Field(
        None, alias='external-id', description='The external id to use for the role'
    )
    use_web_identity: Optional[bool] = Field(
        None,
        alias='use-web-identity',
        description='Whether to use a web identity for authentication',
    )
    access_key_id: Optional[str] = Field(
        None,
        alias='access-key-id',
        description='The access key id to use for the connection',
    )
    secret_access_key: Optional[str] = Field(
        None,
        alias='secret-access-key',
        description='The secret access key to use for the connection',
    )
    session_token: Optional[str] = Field(
        None,
        alias='session-token',
        description='The session token to use for the connection',
    )


class Credential4(BaseModel):
    name: str = Field(
        ..., description="The name of the credential (default = 'default')"
    )
    description: Optional[str] = Field(
        None, description='A description of this credential'
    )
    source_locations: Optional[List[FilePath]] = Field(
        None,
        alias='source-locations',
        description='Credential defined by these set of .sdf files',
    )
    type: Type4
    api_key: str = Field(
        ..., alias='api-key', description='The api key to use for the connection'
    )


class Credential5(BaseModel):
    name: str = Field(
        ..., description="The name of the credential (default = 'default')"
    )
    description: Optional[str] = Field(
        None, description='A description of this credential'
    )
    source_locations: Optional[List[FilePath]] = Field(
        None,
        alias='source-locations',
        description='Credential defined by these set of .sdf files',
    )
    type: Type5


class SyntaxRules(BaseModel):
    class Config:
        extra = 'forbid'

    case_keyword: Optional[Capitalization] = Field(
        None,
        alias='case-keyword',
        description='Inconsistent capitalization of keywords ',
    )
    case_literal: Optional[Capitalization] = Field(
        None,
        alias='case-literal',
        description='Inconsistent capitalization of `boolean`/`null` literal ',
    )
    case_type: Optional[Capitalization] = Field(
        None,
        alias='case-type',
        description='Inconsistent capitalization of datatypes. ',
    )
    case_function: Optional[Capitalization] = Field(
        None,
        alias='case-function',
        description='Inconsistent capitalization of function names ',
    )
    disallow_these_identifiers: Optional[List[str]] = Field(
        None, alias='disallow-these-identifiers', description=''
    )
    flag_keywords_used_as_identifiers: Optional[List[str]] = Field(
        None,
        alias='flag-keywords-used-as-identifiers',
        description='Keywords should not be used as identifiers ',
    )
    disallow_these_chars_in_quoted_identifiers: Optional[str] = Field(
        None,
        alias='disallow-these-chars-in-quoted-identifiers',
        description='Do not use special characters in identifiers ',
    )
    flag_unnecessary_quoted_identifiers: Optional[RuleOn] = Field(
        None,
        alias='flag-unnecessary-quoted-identifiers',
        description='Unnecessary quoted identifier ',
    )
    flag_inconsistent_qualified_column_reference: Optional[ColumnQualifier] = Field(
        None,
        alias='flag-inconsistent-qualified-column-reference',
        description='Inconsistent column references in SELECT clause of both qualified and unqualified references ',
    )
    flag_unqualified_multi_source_column_reference: Optional[RuleOn] = Field(
        None,
        alias='flag-unqualified-multi-source-column-reference',
        description='Columns reference should specify source table or view in queries with more than one source. ',
    )
    flag_inconsistent_ordinal_column_reference: Optional[RuleOn] = Field(
        None,
        alias='flag-inconsistent-ordinal-column-reference',
        description='Inconsistent column references in GROUP BY/ORDER BY clauses of both ordinal and non-ordinal ',
    )
    flag_unnecessary_else: Optional[RuleOn] = Field(
        None,
        alias='flag-unnecessary-else',
        description='Redundant `ELSE NULL` in a case when statement ',
    )
    flag_unnecessary_case: Optional[RuleOn] = Field(
        None,
        alias='flag-unnecessary-case',
        description='CASE statement can be simplified ',
    )
    flag_unused_cte: Optional[RuleOn] = Field(
        None,
        alias='flag-unused-cte',
        description='Query defines a CTE (common-table expression) but does not use it ',
    )
    flag_unnecessary_nested_case: Optional[RuleOn] = Field(
        None,
        alias='flag-unnecessary-nested-case',
        description='Nested CASE statement in ELSE clause could be flattened. ',
    )
    flag_distinct_parenthesis: Optional[RuleOn] = Field(
        None,
        alias='flag-distinct-parenthesis',
        description='DISTINCT used with parentheses ',
    )
    disallow_subquery_in: Optional[List[SubQueryScope]] = Field(
        [],
        alias='disallow-subquery-in',
        description='Join/From clauses should not contain subqueries. Use CTEs instead ',
    )
    flag_misordered_join_condition: Optional[RuleOn] = Field(
        None,
        alias='flag-misordered-join-condition',
        description='Join conditions column references should follow tables reference order ',
    )
    flag_select_item_order: Optional[RuleOn] = Field(
        None,
        alias='flag-select-item-order',
        description='Select wildcards then simple targets before calculations and aggregates. ',
    )
    flag_trailing_semicolon_after_statements: Optional[RuleOn] = Field(
        None,
        alias='flag-trailing-semicolon-after-statements',
        description='Statements should not end with a semi-colon. Multi-statements must be separated with a semi-colon but the final statement should NOT end with one. ',
    )


class SemanticRules(BaseModel):
    class Config:
        extra = 'forbid'

    case_column: Optional[Capitalization] = Field(
        None,
        alias='case-column',
        description='Inconsistent capitalization of column names ',
    )
    case_table: Optional[Capitalization] = Field(
        None,
        alias='case-table',
        description='Inconsistent capitalization of table names ',
    )
    case_alias: Optional[Capitalization] = Field(
        None, alias='case-alias', description='Inconsistent capitalization of alias '
    )
    disallow_implicit_conversions_in: Optional[List[ImplicitConversionOperators]] = (
        Field(
            [],
            alias='disallow-implicit-conversions-in',
            description='Prevent type implicit casting or coercion ',
        )
    )


class IncludePath(BaseModel):
    class Config:
        extra = 'forbid'

    path: str = Field(..., description='A filepath')
    type: Optional[
        Union[
            IncludeType1,
            IncludeType2,
            IncludeType3,
            IncludeType4,
            IncludeType5,
            IncludeType6,
            IncludeType7,
            IncludeType8,
            IncludeType9,
            IncludeType10,
        ]
    ] = Field(
        None,
        description='Type of included artifacts: model | test | stats | metadata | resource',
    )
    index: Optional[
        Union[IndexMethod1, IndexMethod2, IndexMethod3, IndexMethod4, IndexMethod5]
    ] = Field(
        None,
        description='Index method for this include path: scan | table | schema-table | catalog-schema-table',
    )
    defaults: Optional[Defaults] = Field(
        None, description='Defaults for files on this path'
    )


class Environment(BaseModel):
    class Config:
        extra = 'forbid'

    name: str = Field(
        ...,
        description='The name of this workspace (defaults to the workspace directory name if not given) Name must be set for deployment.',
    )
    description: Optional[str] = Field(
        None, description='A description of this workspace'
    )
    repository: Optional[str] = Field(
        None,
        description="The URL of the workspace source repository (defaults to 'none' if no repository is given)",
    )
    includes: Optional[List[IncludePath]] = Field(
        None,
        description='An array of directories and filenames containing .sql and .sdf.yml files',
    )
    excludes: Optional[List[ExcludePath]] = Field(
        None,
        description='An array of directories and filenames to be skipped when resolving includes',
    )
    defaults: Optional[Defaults] = Field(
        None, description='Defaults for this workspace'
    )
    dependencies: Optional[List[Dependency]] = Field(
        None,
        description='Dependencies of the workspace to other workspaces or to cloud database providers',
    )
    integrations: Optional[List[Integration]] = Field(
        None, description='The integrations for this environment'
    )
    vars: Optional[Dict[str, Optional[Union[bool, int, float, str]]]] = Field(
        None,
        description='A map of named values for setting SQL variables from your environment Ex. -dt: dt, used in SQL as @dt, and in Jinja as ',
    )
    source_locations: Optional[List[FilePath]] = Field(
        None,
        alias='source-locations',
        description='Workspace defined by these set of files',
    )
    preprocessor: Optional[Preprocessor] = Field(
        None, description='Experimental: This project has jinja'
    )


class Table(BaseModel):
    class Config:
        extra = 'forbid'

    name: str
    description: Optional[str] = None
    dialect: Optional[Dialect] = Field(
        None, description='The dialect of this table, defaults to `trino`'
    )
    materialization: Optional[
        Union[
            Materialization1,
            Materialization2,
            Materialization3,
            Materialization4,
            Materialization5,
            Materialization6,
            Materialization7,
            Materialization8,
            Materialization9,
            Materialization10,
        ]
    ] = Field(None, description='The table-type of this table (new version)')
    purpose: Optional[
        Union[
            TablePurpose1,
            TablePurpose2,
            TablePurpose3,
            TablePurpose4,
            TablePurpose5,
            TablePurpose6,
            TablePurpose7,
        ]
    ] = Field(None, description='Specify what kind of table or view this is')
    origin: Optional[TableOrigin] = Field(
        None, description='The origin of this table <remote> or <local>'
    )
    exists_remotely: Optional[bool] = Field(
        None,
        alias='exists-remotely',
        description='Whether the table exists in the remote DB (used for is_incremental macro)',
    )
    table_location: Optional[TableLocation] = Field(
        None,
        alias='table-location',
        description='Specify table ,location, defaults to none if not set',
    )
    creation_flags: Optional[
        Union[
            TableCreationFlags1,
            TableCreationFlags2,
            TableCreationFlags3,
            TableCreationFlags4,
            TableCreationFlags5,
        ]
    ] = Field(
        None,
        alias='creation-flags',
        description='Defines the table creation options, defaults to none if not set',
    )
    incremental_options: Optional[IncrementalOptions] = Field(
        None,
        alias='incremental-options',
        description='Options governing incremental table evaluation (only for incremental tables)',
    )
    snapshot_options: Optional[SnapshotOptions] = Field(
        None,
        alias='snapshot-options',
        description='Options governing snapshot table evaluation (only for snapshot tables)',
    )
    dependencies: Optional[List[str]] = Field(
        None,
        description='All tables that this table depends on (syntax: catalog.schema.table)',
    )
    depended_on_by: Optional[List[str]] = Field(
        None,
        alias='depended-on-by',
        description='All tables that depend on this table (syntax: catalog.schema.table)',
    )
    columns: Optional[List[Column]] = Field(
        None, description='The columns of the schema: name, type, metadata'
    )
    partitioned_by: Optional[List[Partition]] = Field(
        None, alias='partitioned-by', description='The partitioning format of the table'
    )
    severity: Optional[Severity] = Field(
        None, description='The default severity for this tables tests and checks'
    )
    tests: Optional[List[Constraint]] = None
    schedule: Optional[str] = Field(
        None, description='The schedule of the table [expressed as cron]'
    )
    starting: Optional[str] = Field(
        None,
        description='The first date of the table [expressed by prefixes of RFC 33]',
    )
    classifiers: Optional[List[str]] = Field(
        None, description='An array of classifier references'
    )
    reclassify: Optional[List[Reclassify]] = Field(
        None,
        description='Array of reclassify instructions for changing the attached classifier labels',
    )
    lineage: Optional[Lineage] = Field(
        None, description='Lineage, a tagged array of column references'
    )
    location: Optional[str] = Field(None, description='Data is at this location')
    file_format: Optional[FileFormat] = Field(
        None,
        alias='file-format',
        description='Store table in this format [only for external tables]',
    )
    with_header: Optional[bool] = Field(
        None,
        alias='with-header',
        description='CSV data has a header [only for external tables]',
    )
    delimiter: Optional[str] = Field(
        None,
        description='CSV data is separated by this delimiter [only for external tables]',
    )
    compression: Optional[
        Union[CompressionType1, CompressionType2, CompressionType3, CompressionType4]
    ] = Field(
        None,
        description='Json or CSV data is compressed with this method [only for external tables]',
    )
    cycle_cut_point: Optional[bool] = Field(
        None,
        alias='cycle-cut-point',
        description='If this table is part of a cyclic dependency then cut the cycle here',
    )
    source_locations: Optional[List[FilePath]] = Field(
        None,
        alias='source-locations',
        description='Table is defined by these .sql and/or .sdf files',
    )
    sealed: Optional[bool] = Field(
        None,
        description="This table is either backed by a create table ddl or by a table definition in yml that is the table's complete schema",
    )
    meta: Optional[Dict[str, str]] = Field(None, description='Metadata for this table')


class Function(BaseModel):
    class Config:
        extra = 'forbid'

    name: str = Field(
        ...,
        description='The name of the function [syntax: [[catalog.]schema].function]',
    )
    section: Optional[str] = Field(None, description='The generic type bounds')
    dialect: Optional[Dialect] = Field(
        None, description='The dialect that provides this function'
    )
    description: Optional[str] = Field(
        None, description='A description of this function'
    )
    variadic: Optional[Union[Variadic1, Variadic2, Variadic3, Variadic4]] = Field(
        None,
        description='Arbitrary number of arguments of an common type out of a list of valid types',
    )
    kind: Optional[FunctionKind] = Field(None, description='The function kind')
    parameters: Optional[List[Parameter]] = Field(
        None, description='The arguments of this function'
    )
    optional_parameters: Optional[List[OptionalParameter]] = Field(
        None, alias='optional-parameters', description='The arguments of this function'
    )
    returns: Optional[Parameter] = Field(
        None, description='The results of this function (can be a tuple)'
    )
    binds: Optional[List[TypeBound]] = Field(
        None, description='The generic type bounds'
    )
    volatility: Optional[Union[Volatility1, Volatility2, Volatility3]] = Field(
        None, description='volatility - The volatility of the function.'
    )
    examples: Optional[List[Example]] = Field(
        None,
        description='example - Example use of the function (tuple with input/output)',
    )
    cross_link: Optional[str] = Field(
        None,
        alias='cross-link',
        description='cross-link - link to existing documentation, for example: https://trino.io/docs/current/functions/datetime.html#date_trunc',
    )
    reclassify: Optional[List[Reclassify]] = Field(
        None,
        description='Array of reclassify instructions for changing the attached classifier labels',
    )
    source_locations: Optional[List[FilePath]] = Field(
        None,
        alias='source-locations',
        description='Function defined by these set of .sdf files',
    )
    implemented_by: Optional[
        Union[
            FunctionImplSpec1, FunctionImplSpec2, FunctionImplSpec3, FunctionImplSpec4
        ]
    ] = Field(None, alias='implemented-by')
    special: Optional[bool] = Field(
        None,
        description='Function can be called without parentheses, e.g. as if it were a constant, e.g. current_date',
    )


class Linter(BaseModel):
    class Config:
        extra = 'forbid'

    name: Optional[str] = Field(
        '',
        description='The name of these lint rules, e.g. "my_rules", can be referenced in defaults',
    )
    layout_rules: Optional[LayoutRules] = Field(
        None, alias='layout-rules', description='These rules check for proper spacing'
    )
    syntax_rules: Optional[SyntaxRules] = Field(None, alias='syntax-rules')
    semantic_rules: Optional[SemanticRules] = Field(None, alias='semantic-rules')
    performance_rules: Optional[PerformanceRules] = Field(
        None, alias='performance-rules'
    )
    check_rules: Optional[Dict[str, Any]] = Field(None, alias='check-rules')


class Workspace(BaseModel):
    class Config:
        extra = 'forbid'

    edition: str = Field(
        ..., description='The SDF edition, should always be 1.3 (1.2 is deprecated)'
    )
    name: str = Field(
        ...,
        description='The name of this workspace (defaults to the workspace directory name if not given) Name must be set for deployment.',
    )
    description: Optional[str] = Field(
        None, description='A description of this workspace'
    )
    repository: Optional[str] = Field(
        None,
        description="The URL of the workspace source repository (defaults to 'none' if no repository is given)",
    )
    includes: Optional[List[IncludePath]] = Field(
        None,
        description='An array of directories and filenames containing .sql and .sdf.yml files',
    )
    excludes: Optional[List[ExcludePath]] = Field(
        None,
        description='An array of directories and filenames to be skipped when resolving includes',
    )
    dependencies: Optional[List[Dependency]] = Field(
        None,
        description='Dependencies of the workspace to other workspaces or to cloud database providers',
    )
    integrations: Optional[List[Integration]] = Field(
        None, description='The integrations for this environment'
    )
    defaults: Optional[Defaults] = Field(
        None, description='Defaults for this workspace'
    )
    source_locations: Optional[List[FilePath]] = Field(
        None,
        alias='source-locations',
        description='Workspace defined by these set of files',
    )
    vars: Optional[Dict[str, Optional[Union[bool, int, float, str]]]] = Field(
        None,
        description='A map of named values for setting SQL variables from your environment Ex. -dt: dt, used in SQL as @dt, and in Jinja as ',
    )


class Definition(BaseModel):
    class Config:
        extra = 'forbid'

    workspace: Optional[Workspace] = Field(None, description='A workspace definition')
    environment: Optional[Environment] = Field(
        None, description='A environment definition'
    )
    table: Optional[Table] = Field(None, description='A table definition')
    classifier: Optional[Classifier] = Field(
        None, description='A classifier definition'
    )
    function: Optional[Function] = Field(None, description='A function definition')
    config: Optional[Config] = Field(None, description='A config definition')
    credential: Optional[
        Union[Credential1, Credential2, Credential3, Credential4, Credential5]
    ] = Field(None, description='A credential definition')
    linter: Optional[Linter] = Field(None, description='A config definition')
